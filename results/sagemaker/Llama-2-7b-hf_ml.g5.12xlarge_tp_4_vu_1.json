{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 4,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 102,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 61.45733053769864,
  "Latency (ms/token) avg": 18.841357392156862,
  "Latency (ms/token) min": 15.254187,
  "Latency (ms/token) med": 16.812526,
  "Latency (ms/token) max": 85.344764,
  "Latency (ms/token) p(90)": 19.7687088,
  "Latency (ms/token) p(95)": 20.438907899999997,
  "Latency Request ms p(90)": 934.8573862000001,
  "Latency Request ms p(95)": 988.9880079999999,
  "Latency Request ms avg": 813.5725968333334,
  "Latency Request ms min": 76.368003,
  "Latency Request ms med": 825.7631015,
  "Latency Request ms max": 1021.9159980000001,
  "Latency Infernece ms med": 825.2258575000001,
  "Latency Infernece ms max": 1019.400295,
  "Latency Infernece ms p(90)": 933.2562455,
  "Latency Infernece ms p(95)": 987.53788275,
  "Latency Infernece ms avg": 812.5959722549019,
  "Latency Infernece ms min": 75.748603,
  "Queue time ms med": 0.044051,
  "Queue time ms max": 0.106312,
  "Queue time ms p(90)": 0.05916400000000001,
  "Queue time ms p(95)": 0.0649555,
  "Queue time ms avg": 0.04855555882352941,
  "Queue time ms min": 0.035631
}