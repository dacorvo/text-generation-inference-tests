{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 2,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 518,
  "Virtual Users": 20,
  "Thorughput (tokens/second)": 295.1977007710839,
  "Latency (ms/token) avg": 73.20746744980694,
  "Latency (ms/token) min": 31.35872,
  "Latency (ms/token) med": 66.414507,
  "Latency (ms/token) max": 612.797788,
  "Latency (ms/token) p(90)": 83.71753149999999,
  "Latency (ms/token) p(95)": 98.13578460000001,
  "Latency Request ms p(90)": 4219.5538323,
  "Latency Request ms p(95)": 4921.9802297,
  "Latency Request ms avg": 3387.5602600830116,
  "Latency Request ms min": 419.896286,
  "Latency Request ms med": 3401.8151344999997,
  "Latency Request ms max": 6461.095886,
  "Latency Infernece ms med": 3269.075137,
  "Latency Infernece ms max": 4937.632271,
  "Latency Infernece ms p(90)": 4001.1587069999996,
  "Latency Infernece ms p(95)": 4255.609073,
  "Latency Infernece ms avg": 3194.9696309266405,
  "Latency Infernece ms min": 328.669388,
  "Queue time ms med": 146.5867745,
  "Queue time ms max": 2817.147306,
  "Queue time ms p(90)": 195.5062803,
  "Queue time ms p(95)": 400.1233450499998,
  "Queue time ms avg": 191.70413203088805,
  "Queue time ms min": 0.050901
}