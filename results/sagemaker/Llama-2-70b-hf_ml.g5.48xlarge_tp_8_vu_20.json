{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-70b-hf",
  "Instance": "ml.g5.48xlarge",
  "Tensor parallelism degree": 8,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 96,
  "Virtual Users": 20,
  "Duration (s)": 90,
"Throughput (tokens/second)": 51.601566662176026,
  "Latency (ms/token) avg": 831.06627559375,
  "Latency (ms/token) min": 252.143602,
  "Latency (ms/token) med": 413.15819450000004,
  "Latency (ms/token) max": 11205.405518,
  "Latency (ms/token) p(90)": 501.6297585,
  "Latency (ms/token) p(95)": 4878.11174975,
  "Latency Request ms p(90)": 25122.9083255,
  "Latency Request ms p(95)": 27637.72956975,
  "Latency Request ms avg": 19379.25657464583,
  "Latency Request ms min": 2457.553551,
  "Latency Request ms med": 20491.023774,
  "Latency Request ms max": 36103.153516,
  "Latency Inference ms med": 20448.840835000003,
  "Latency Inference ms max": 25081.728433999997,
  "Latency Inference ms p(90)": 24430.483171,
  "Latency Inference ms p(95)": 25081.234143499998,
  "Latency Inference ms avg": 18233.315352427086,
  "Latency Inference ms min": 2332.98248,
  "Queue time ms med": 75.504653,
  "Queue time ms max": 13127.324080999999,
  "Queue time ms p(90)": 1450.7367605,
  "Queue time ms p(95)": 4437.56572375,
  "Queue time ms avg": 1144.9791225833335,
  "Queue time ms min": 0.098361
}