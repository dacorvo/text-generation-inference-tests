{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 228,
  "Virtual Users": 5,
  "Thorughput (tokens/second)": 130.9298241989885,
  "Latency (ms/token) avg": 39.50523528508772,
  "Latency (ms/token) min": 32.902507,
  "Latency (ms/token) med": 37.941161,
  "Latency (ms/token) max": 140.055411,
  "Latency (ms/token) p(90)": 42.7877406,
  "Latency (ms/token) p(95)": 44.176681599999995,
  "Latency Request ms p(90)": 2217.6938877000002,
  "Latency Request ms p(95)": 2286.8434216,
  "Latency Request ms avg": 1909.419809653509,
  "Latency Request ms min": 111.211953,
  "Latency Request ms med": 1917.501299,
  "Latency Request ms max": 2879.964227,
  "Latency Infernece ms med": 1873.493301,
  "Latency Infernece ms max": 2401.963601,
  "Latency Infernece ms p(90)": 2120.2929735,
  "Latency Infernece ms p(95)": 2172.45335915,
  "Latency Infernece ms avg": 1848.9109936359648,
  "Latency Infernece ms min": 87.123353,
  "Queue time ms med": 23.415514,
  "Queue time ms max": 749.822534,
  "Queue time ms p(90)": 67.53058900000002,
  "Queue time ms p(95)": 260.4351707999998,
  "Queue time ms avg": 59.52701310526315,
  "Queue time ms min": 0.03107
}