{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 214,
  "Virtual Users": 5,
  "Thorughput (tokens/second)": 131.29113826365776,
  "Latency (ms/token) avg": 39.557847317757,
  "Latency (ms/token) min": 32.899389,
  "Latency (ms/token) med": 37.936685,
  "Latency (ms/token) max": 139.885096,
  "Latency (ms/token) p(90)": 42.7317541,
  "Latency (ms/token) p(95)": 44.093923,
  "Latency Request ms p(90)": 2174.5768779,
  "Latency Request ms p(95)": 2296.50276705,
  "Latency Request ms avg": 1904.1650739439253,
  "Latency Request ms min": 110.681419,
  "Latency Request ms med": 1918.5163985,
  "Latency Request ms max": 2880.086346,
  "Latency Infernece ms med": 1871.3208235,
  "Latency Infernece ms max": 2402.355009,
  "Latency Infernece ms p(90)": 2119.6647107,
  "Latency Infernece ms p(95)": 2158.9726564,
  "Latency Infernece ms avg": 1844.3958182850467,
  "Latency Infernece ms min": 86.978253,
  "Queue time ms med": 22.610304999999997,
  "Queue time ms max": 751.920707,
  "Queue time ms p(90)": 101.08145860000084,
  "Queue time ms p(95)": 262.6706225,
  "Queue time ms avg": 58.78435089252336,
  "Queue time ms min": 0.04224
}