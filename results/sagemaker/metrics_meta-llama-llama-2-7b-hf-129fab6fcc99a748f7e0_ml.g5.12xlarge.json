{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 4,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 69,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 56.9299267511576,
  "Latency (ms/token) avg": 19.033217840579713,
  "Latency (ms/token) min": 16.131319,
  "Latency (ms/token) med": 17.306793,
  "Latency (ms/token) max": 91.148095,
  "Latency (ms/token) p(90)": 20.5923858,
  "Latency (ms/token) p(95)": 21.321774,
  "Latency Request ms p(90)": 1014.8279565999999,
  "Latency Request ms p(95)": 1060.8696112,
  "Latency Request ms avg": 878.2726915942029,
  "Latency Request ms min": 183.692411,
  "Latency Request ms med": 856.93106,
  "Latency Request ms max": 1077.069088,
  "Latency Infernece ms med": 856.367983,
  "Latency Infernece ms max": 1074.180337,
  "Latency Infernece ms p(90)": 1012.9358668,
  "Latency Infernece ms p(95)": 1058.3987734,
  "Latency Infernece ms avg": 877.2878242463769,
  "Latency Infernece ms min": 182.296191,
  "Queue time ms med": 0.045869999999999994,
  "Queue time ms max": 0.08154,
  "Queue time ms p(90)": 0.05936620000000001,
  "Queue time ms p(95)": 0.0631296,
  "Queue time ms avg": 0.04876779710144928,
  "Queue time ms min": 0.034790999999999996
}