{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-13b-hf", "Instance": "ml.g5.48xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 296, "Virtual Users": 10, "Throughput (tokens/second)": 168.32272164778917, "Latency (ms/token) avg": 82.95012803378378, "Latency (ms/token) min": 27.220042, "Latency (ms/token) med": 60.013692, "Latency (ms/token) max": 1214.02415, "Latency (ms/token) p(90)": 77.506597, "Latency (ms/token) p(95)": 83.3501345, "Latency Request ms p(90)": 3880.864146, "Latency Request ms p(95)": 4099.99450275, "Latency Request ms avg": 2970.484288189189, "Latency Request ms min": 255.051568, "Latency Request ms med": 2901.8564914999997, "Latency Request ms max": 4846.478217999999, "Latency Inference ms med": 2879.1427445, "Latency Inference ms max": 4413.734332999999, "Latency Inference ms p(90)": 3849.6993245000003, "Latency Inference ms p(95)": 3995.2194345, "Latency Inference ms avg": 2898.927026824324, "Latency Inference ms min": 151.942034, "Queue time ms med": 28.7491615, "Queue time ms max": 1227.94969, "Queue time ms p(90)": 167.68052649999998, "Queue time ms p(95)": 317.67473025000004, "Queue time ms avg": 70.54884878378377, "Queue time ms min": 0.02761}