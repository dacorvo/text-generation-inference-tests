{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.p4d.24xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 387,
  "Virtual Users": 5,
  "Thorughput (tokens/second)": 244.5369823829679,
  "Latency (ms/token) avg": 20.65282166149871,
  "Latency (ms/token) min": 15.189063,
  "Latency (ms/token) med": 18.763008,
  "Latency (ms/token) max": 146.661216,
  "Latency (ms/token) p(90)": 24.0188406,
  "Latency (ms/token) p(95)": 27.65408,
  "Latency Request ms p(90)": 1287.0661092,
  "Latency Request ms p(95)": 1397.2649823,
  "Latency Request ms avg": 1022.3402512118862,
  "Latency Request ms min": 70.291595,
  "Latency Request ms med": 1015.2727399999999,
  "Latency Request ms max": 1980.18918,
  "Latency Infernece ms med": 926.787519,
  "Latency Infernece ms max": 1651.641166,
  "Latency Infernece ms p(90)": 1142.4976577999998,
  "Latency Infernece ms p(95)": 1216.2927881,
  "Latency Infernece ms avg": 925.5178030723514,
  "Latency Infernece ms min": 46.163551,
  "Queue time ms med": 43.439779,
  "Queue time ms max": 444.214888,
  "Queue time ms p(90)": 269.2890064,
  "Queue time ms p(95)": 304.6455288,
  "Queue time ms avg": 96.00646414470283,
  "Queue time ms min": 0.041399
}