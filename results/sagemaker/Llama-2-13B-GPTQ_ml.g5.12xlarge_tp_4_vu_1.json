{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-13B-GPTQ", "Instance": "ml.g5.12xlarge", "Tensor parallelism degree": 4, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 47, "Virtual Users": 1, "Thorughput (tokens/second)": 27.468495179320424, "Latency (ms/token) avg": 36.39998340425531, "Latency (ms/token) min": 25.862243, "Latency (ms/token) med": 28.17885, "Latency (ms/token) max": 136.751145, "Latency (ms/token) p(90)": 62.151353799999995, "Latency (ms/token) p(95)": 69.13353269999996, "Latency Request ms p(90)": 3109.2807338, "Latency Request ms p(95)": 3457.1844515999983, "Latency Request ms avg": 1820.267170574468, "Latency Request ms min": 1293.445484, "Latency Request ms med": 1409.9843540000002, "Latency Request ms max": 6838.17056, "Latency Infernece ms med": 1408.942503, "Latency Infernece ms max": 6837.5572870000005, "Latency Infernece ms p(90)": 3107.5677116, "Latency Infernece ms p(95)": 3456.676658499998, "Latency Infernece ms avg": 1819.3318685106383, "Latency Infernece ms min": 1293.112197, "Queue time ms med": 0.045501, "Queue time ms max": 0.111192, "Queue time ms p(90)": 0.07239499999999999, "Queue time ms p(95)": 0.078772, "Queue time ms avg": 0.05272717021276595, "Queue time ms min": 0.032451}