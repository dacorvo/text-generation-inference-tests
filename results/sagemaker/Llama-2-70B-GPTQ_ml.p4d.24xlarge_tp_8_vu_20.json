{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-70B-GPTQ", "Instance": "ml.p4d.24xlarge", "Tensor parallelism degree": 8, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 270, "Virtual Users": 20, "Throughput (tokens/second)": 147.50231042313064, "Latency (ms/token) avg": 165.24339316666666, "Latency (ms/token) min": 76.617111, "Latency (ms/token) med": 116.46342849999999, "Latency (ms/token) max": 4444.792062, "Latency (ms/token) p(90)": 280.180663, "Latency (ms/token) p(95)": 280.1876234, "Latency Request ms p(90)": 8009.605704, "Latency Request ms p(95)": 19203.3092109, "Latency Request ms avg": 6779.554822777777, "Latency Request ms min": 685.591511, "Latency Request ms med": 6077.621547500001, "Latency Request ms max": 19306.813610999998, "Latency Inference ms med": 5650.879221, "Latency Inference ms max": 19306.393869, "Latency Inference ms p(90)": 7506.428683, "Latency Inference ms p(95)": 14009.07504095, "Latency Inference ms avg": 6063.974838296296, "Latency Inference ms min": 422.008619, "Queue time ms med": 417.0465585, "Queue time ms max": 5297.239302999999, "Queue time ms p(90)": 1268.985192799998, "Queue time ms p(95)": 5192.7756076, "Queue time ms avg": 714.3300307481481, "Queue time ms min": 0.047796}