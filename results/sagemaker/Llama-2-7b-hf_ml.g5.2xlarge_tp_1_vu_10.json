{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 352,
  "Virtual Users": 10,
  "Thorughput (tokens/second)": 214.7900272136794,
  "Latency (ms/token) avg": 48.40123622727273,
  "Latency (ms/token) min": 33.802133,
  "Latency (ms/token) med": 45.488243499999996,
  "Latency (ms/token) max": 365.770418,
  "Latency (ms/token) p(90)": 52.0858784,
  "Latency (ms/token) p(95)": 54.975192050000004,
  "Latency Request ms p(90)": 2746.4357365,
  "Latency Request ms p(95)": 2822.3920625,
  "Latency Request ms avg": 2327.8548193607953,
  "Latency Request ms min": 166.992246,
  "Latency Request ms med": 2358.6754255,
  "Latency Request ms max": 3302.488238,
  "Latency Infernece ms med": 2245.110751,
  "Latency Infernece ms max": 3024.2320870000003,
  "Latency Infernece ms p(90)": 2560.7464444,
  "Latency Infernece ms p(95)": 2624.62280445,
  "Latency Infernece ms avg": 2215.5502067102275,
  "Latency Infernece ms min": 126.187456,
  "Queue time ms med": 28.530872000000002,
  "Queue time ms max": 914.5485,
  "Queue time ms p(90)": 196.7992299,
  "Queue time ms p(95)": 203.8065999,
  "Queue time ms avg": 111.13118726704546,
  "Queue time ms min": 0.042761
}