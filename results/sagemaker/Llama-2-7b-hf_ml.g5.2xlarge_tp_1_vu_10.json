{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 387,
  "Virtual Users": 10,
  "Thorughput (tokens/second)": 220.05522274296806,
  "Latency (ms/token) avg": 47.38081088630491,
  "Latency (ms/token) min": 37.033215,
  "Latency (ms/token) med": 44.930824,
  "Latency (ms/token) max": 363.998309,
  "Latency (ms/token) p(90)": 52.2996554,
  "Latency (ms/token) p(95)": 55.01323079999999,
  "Latency Request ms p(90)": 2642.8880862000005,
  "Latency Request ms p(95)": 2832.5330821999996,
  "Latency Request ms avg": 2272.156933007752,
  "Latency Request ms min": 136.008882,
  "Latency Request ms med": 2277.413242,
  "Latency Request ms max": 3104.986438,
  "Latency Infernece ms med": 2201.356687,
  "Latency Infernece ms max": 3028.317353,
  "Latency Infernece ms p(90)": 2592.017506,
  "Latency Infernece ms p(95)": 2643.714398,
  "Latency Infernece ms avg": 2204.7940329224807,
  "Latency Infernece ms min": 88.896878,
  "Queue time ms med": 24.630629,
  "Queue time ms max": 869.59049,
  "Queue time ms p(90)": 192.39002820000002,
  "Queue time ms p(95)": 201.85311249999998,
  "Queue time ms avg": 66.24399712403101,
  "Queue time ms min": 0.065841
}