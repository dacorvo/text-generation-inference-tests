{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-13b-hf", "Instance": "ml.g5.48xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 349, "Virtual Users": 20, "Duration (s)": 90,
"Throughput (tokens/second)": 195.13379788568713, "Latency (ms/token) avg": 130.34982340114615, "Latency (ms/token) min": 62.247153, "Latency (ms/token) med": 103.09154, "Latency (ms/token) max": 2164.227926, "Latency (ms/token) p(90)": 132.9578016, "Latency (ms/token) p(95)": 138.2306778, "Latency Request ms p(90)": 6773.6816936, "Latency Request ms p(95)": 6932.0153066, "Latency Request ms avg": 5124.688858799427, "Latency Request ms min": 831.265894, "Latency Request ms med": 5203.261377999999, "Latency Request ms max": 10244.253902, "Latency Inference ms med": 5135.25356, "Latency Inference ms max": 6950.199401, "Latency Inference ms p(90)": 6438.0160102, "Latency Inference ms p(95)": 6749.311722, "Latency Inference ms avg": 4878.471695031519, "Latency Inference ms min": 710.865414, "Queue time ms med": 120.782776, "Queue time ms max": 4503.411885, "Queue time ms p(90)": 411.67158, "Queue time ms p(95)": 456.8493702, "Queue time ms avg": 244.95120412320912, "Queue time ms min": 0.030521}