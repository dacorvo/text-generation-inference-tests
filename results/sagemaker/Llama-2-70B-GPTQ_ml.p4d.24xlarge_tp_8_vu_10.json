{
  "Host": "sagemaker",
  "Model Id": "TheBloke/Llama-2-70B-GPTQ",
  "Instance": "ml.p4d.24xlarge",
  "Tensor parallelism degree": 8,
  "quantization": "gptq",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 164,
  "Virtual Users": 10,
  "Duration (s)": 90,
"Throughput (tokens/second)": 90.71305109798847,
  "Latency (ms/token) avg": 130.31929477439024,
  "Latency (ms/token) min": 70.665613,
  "Latency (ms/token) med": 94.930653,
  "Latency (ms/token) max": 1618.608857,
  "Latency (ms/token) p(90)": 164.1251025,
  "Latency (ms/token) p(95)": 299.2974697999998,
  "Latency Request ms p(90)": 7749.4591603,
  "Latency Request ms p(95)": 12738.800973049974,
  "Latency Request ms avg": 5511.886040079268,
  "Latency Request ms min": 401.123981,
  "Latency Request ms med": 4839.4227875,
  "Latency Request ms max": 13483.229522,
  "Latency Inference ms med": 4575.672943,
  "Latency Inference ms max": 13482.927090000001,
  "Latency Inference ms p(90)": 6700.5177264,
  "Latency Inference ms p(95)": 8134.492433949998,
  "Latency Inference ms avg": 4837.945008512196,
  "Latency Inference ms min": 351.133402,
  "Queue time ms med": 55.821837,
  "Queue time ms max": 5276.3795900000005,
  "Queue time ms p(90)": 1949.5478113,
  "Queue time ms p(95)": 4881.764721349987,
  "Queue time ms avg": 672.6183763536585,
  "Queue time ms min": 0.029703
}