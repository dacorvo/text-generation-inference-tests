{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 53,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 31.35732773773528,
  "Latency (ms/token) avg": 32.340221981132075,
  "Latency (ms/token) min": 30.737704,
  "Latency (ms/token) med": 31.234704,
  "Latency (ms/token) max": 37.212203,
  "Latency (ms/token) p(90)": 34.6799574,
  "Latency (ms/token) p(95)": 35.342228199999994,
  "Latency Request ms p(90)": 1735.7590012,
  "Latency Request ms p(95)": 1769.1034307999998,
  "Latency Request ms avg": 1594.5236283584907,
  "Latency Request ms min": 436.365832,
  "Latency Request ms med": 1555.699167,
  "Latency Request ms max": 1863.380536,
  "Latency Infernece ms med": 1555.158737,
  "Latency Infernece ms max": 1860.61017,
  "Latency Infernece ms p(90)": 1733.9978962,
  "Latency Infernece ms p(95)": 1767.1114506,
  "Latency Infernece ms avg": 1593.607896075472,
  "Latency Infernece ms min": 435.806073,
  "Queue time ms med": 0.04537,
  "Queue time ms max": 0.068022,
  "Queue time ms p(90)": 0.055200000000000006,
  "Queue time ms p(95)": 0.0574796,
  "Queue time ms avg": 0.04700758490566038,
  "Queue time ms min": 0.036761
}