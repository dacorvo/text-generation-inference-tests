{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-13B-GPTQ", "Instance": "ml.g5.2xlarge", "Tensor parallelism degree": 1, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 218, "Virtual Users": 20, "Duration (s)": 90,
"Throughput (tokens/second)": 127.29601570957918, "Latency (ms/token) avg": 169.48634483027521, "Latency (ms/token) min": 89.557095, "Latency (ms/token) med": 135.4301335, "Latency (ms/token) max": 2310.901393, "Latency (ms/token) p(90)": 233.4618369, "Latency (ms/token) p(95)": 242.1411941999987, "Latency Request ms p(90)": 10484.202416299999, "Latency Request ms p(95)": 15964.908171949999, "Latency Request ms avg": 7855.705415646789, "Latency Request ms min": 1056.614058, "Latency Request ms med": 7122.636137, "Latency Request ms max": 16011.390204000001, "Latency Inference ms med": 6391.4710235, "Latency Inference ms max": 16011.01327, "Latency Inference ms p(90)": 8686.265064300002, "Latency Inference ms p(95)": 11673.1359055, "Latency Inference ms avg": 6868.496654995413, "Latency Inference ms min": 532.634164, "Queue time ms med": 465.425177, "Queue time ms max": 5572.177204, "Queue time ms p(90)": 4025.2261999999996, "Queue time ms p(95)": 4290.005755, "Queue time ms avg": 985.6171873669725, "Queue time ms min": 0.059461}