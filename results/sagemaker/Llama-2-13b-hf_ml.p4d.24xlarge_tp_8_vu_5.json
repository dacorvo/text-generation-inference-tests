{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-13b-hf", "Instance": "ml.p4d.24xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 340, "Virtual Users": 5, "Thorughput (tokens/second)": 199.83937009047784, "Latency (ms/token) avg": 24.705311308823525, "Latency (ms/token) min": 22.349537, "Latency (ms/token) med": 24.296073, "Latency (ms/token) max": 44.05325, "Latency (ms/token) p(90)": 26.501194299999998, "Latency (ms/token) p(95)": 27.6050163, "Latency Request ms p(90)": 1439.1912772, "Latency Request ms p(95)": 1513.70247325, "Latency Request ms avg": 1251.0047438941176, "Latency Request ms min": 59.174117, "Latency Request ms med": 1290.2939929999998, "Latency Request ms max": 1695.943206, "Latency Infernece ms med": 1211.4597285, "Latency Infernece ms max": 1416.972509, "Latency Infernece ms p(90)": 1288.1344093, "Latency Infernece ms p(95)": 1344.0941249500002, "Latency Infernece ms avg": 1170.8405271941178, "Latency Infernece ms min": 26.304646, "Queue time ms med": 89.569834, "Queue time ms max": 498.182627, "Queue time ms p(90)": 145.2624969, "Queue time ms p(95)": 273.30847845, "Queue time ms avg": 79.27377567058822, "Queue time ms min": 0.022611}