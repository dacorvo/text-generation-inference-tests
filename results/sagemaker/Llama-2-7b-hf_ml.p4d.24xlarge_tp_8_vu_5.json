{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-7b-hf", "Instance": "ml.p4d.24xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 259, "Virtual Users": 5, "Throughput (tokens/second)": 149.2002724662508, "Latency (ms/token) avg": 36.25556326640927, "Latency (ms/token) min": 22.299721, "Latency (ms/token) med": 33.902706, "Latency (ms/token) max": 219.062775, "Latency (ms/token) p(90)": 37.7328714, "Latency (ms/token) p(95)": 39.807006, "Latency Request ms p(90)": 1960.9705498, "Latency Request ms p(95)": 2044.9993607000001, "Latency Request ms avg": 1675.6001572084945, "Latency Request ms min": 226.516514, "Latency Request ms med": 1767.791246, "Latency Request ms max": 2513.3603359999997, "Latency Inference ms med": 1612.929649, "Latency Inference ms max": 2112.761121, "Latency Inference ms p(90)": 1867.1895668, "Latency Inference ms p(95)": 1893.1991847, "Latency Inference ms avg": 1596.956915830116, "Latency Inference ms min": 219.062775, "Queue time ms med": 14.009318, "Queue time ms max": 670.991451, "Queue time ms p(90)": 255.0753190000001, "Queue time ms p(95)": 283.2092325, "Queue time ms avg": 77.50567547876447, "Queue time ms min": 0.026091}