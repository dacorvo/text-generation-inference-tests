{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-13b-hf", "Instance": "ml.g5.12xlarge", "Tensor parallelism degree": 4, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 396, "Virtual Users": 10, "Duration (s)": 90,
"Throughput (tokens/second)": 226.0872252662919, "Latency (ms/token) avg": 54.06696063636364, "Latency (ms/token) min": 28.894848, "Latency (ms/token) med": 43.5169825, "Latency (ms/token) max": 718.60198, "Latency (ms/token) p(90)": 56.728798, "Latency (ms/token) p(95)": 66.31662775000001, "Latency Request ms p(90)": 2827.235088, "Latency Request ms p(95)": 2964.98782075, "Latency Request ms avg": 2211.535832734848, "Latency Request ms min": 165.163642, "Latency Request ms med": 2194.5149645, "Latency Request ms max": 3855.958502, "Latency Inference ms med": 2083.701989, "Latency Inference ms max": 3315.8872029999998, "Latency Inference ms p(90)": 2719.8101515, "Latency Inference ms p(95)": 2836.5249395, "Latency Inference ms avg": 2123.891391659091, "Latency Inference ms min": 143.952591, "Queue time ms med": 63.029525, "Queue time ms max": 1449.248242, "Queue time ms p(90)": 120.36086449999999, "Queue time ms p(95)": 296.3145875, "Queue time ms avg": 86.70737278282827, "Queue time ms min": 0.03471}