{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 166,
  "Virtual Users": 5,
  "Thorughput (tokens/second)": 109.0638947792487,
  "Latency (ms/token) avg": 47.31314940963855,
  "Latency (ms/token) min": 33.87464,
  "Latency (ms/token) med": 43.836155500000004,
  "Latency (ms/token) max": 289.412446,
  "Latency (ms/token) p(90)": 53.632294,
  "Latency (ms/token) p(95)": 58.677616,
  "Latency Request ms p(90)": 2817.495347,
  "Latency Request ms p(95)": 3058.41690075,
  "Latency Request ms avg": 2292.2342953734938,
  "Latency Request ms min": 238.671377,
  "Latency Request ms med": 2304.5013665,
  "Latency Request ms max": 3572.961388,
  "Latency Infernece ms med": 2135.414344,
  "Latency Infernece ms max": 2984.297784,
  "Latency Infernece ms p(90)": 2552.649131,
  "Latency Infernece ms p(95)": 2750.90481275,
  "Latency Infernece ms avg": 2098.268346674699,
  "Latency Infernece ms min": 216.020063,
  "Queue time ms med": 177.7036655,
  "Queue time ms max": 1161.4038360000002,
  "Queue time ms p(90)": 407.95706399999995,
  "Queue time ms p(95)": 576.1181315,
  "Queue time ms avg": 193.08884617469877,
  "Queue time ms min": 0.041210000000000004
}