{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 186,
  "Virtual Users": 5,
  "Thorughput (tokens/second)": 108.15783549836591,
  "Latency (ms/token) avg": 46.388869494623655,
  "Latency (ms/token) min": 34.026255,
  "Latency (ms/token) med": 43.697665,
  "Latency (ms/token) max": 134.219606,
  "Latency (ms/token) p(90)": 55.0574655,
  "Latency (ms/token) p(95)": 64.42011725,
  "Latency Request ms p(90)": 2839.5732795,
  "Latency Request ms p(95)": 3069.6702645,
  "Latency Request ms avg": 2311.436789096774,
  "Latency Request ms min": 182.274792,
  "Latency Request ms med": 2261.754734,
  "Latency Request ms max": 3682.6155479999998,
  "Latency Infernece ms med": 2141.731645,
  "Latency Infernece ms max": 3354.808497,
  "Latency Infernece ms p(90)": 2580.614004,
  "Latency Infernece ms p(95)": 2771.41129175,
  "Latency Infernece ms avg": 2137.5735735215053,
  "Latency Infernece ms min": 134.219606,
  "Queue time ms med": 140.604737,
  "Queue time ms max": 900.992781,
  "Queue time ms p(90)": 295.469982,
  "Queue time ms p(95)": 621.6343159999999,
  "Queue time ms avg": 172.92933469892472,
  "Queue time ms min": 0.042161000000000004
}