{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-70B-GPTQ", "Instance": "ml.g5.48xlarge", "Tensor parallelism degree": 8, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 72, "Virtual Users": 10, "Duration (s)": 90,
"Throughput (tokens/second)": 39.61647879082929, "Latency (ms/token) avg": 379.9064921111111, "Latency (ms/token) min": 95.791928, "Latency (ms/token) med": 234.54207, "Latency (ms/token) max": 4524.220386999999, "Latency (ms/token) p(90)": 329.8612339, "Latency (ms/token) p(95)": 824.8732000000025, "Latency Request ms p(90)": 22069.5605261, "Latency Request ms p(95)": 22072.9368647, "Latency Request ms avg": 12621.010631458332, "Latency Request ms min": 2630.733347, "Latency Request ms med": 11714.9389125, "Latency Request ms max": 22092.491770999997, "Latency Inference ms med": 11675.7326485, "Latency Inference ms max": 22091.985843, "Latency Inference ms p(90)": 16449.8137703, "Latency Inference ms p(95)": 16493.01467445, "Latency Inference ms avg": 11352.002411458334, "Latency Inference ms min": 2586.050473, "Queue time ms med": 75.617305, "Queue time ms max": 6024.631544, "Queue time ms p(90)": 6007.2083328, "Queue time ms p(95)": 6008.1206539, "Queue time ms avg": 1268.0585007222223, "Queue time ms min": 0.050301}