{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-13b-hf",
  "Instance": "ml.inf2.48xlarge",
  "Tensor parallelism degree": 24,
  "quantization": "none",
  "generated_tokens per request": 500,
  "Do Sample": true,
  "Number of requests": 81,
  "Virtual Users": 5,
  "Duration (s)": 192,
  "Throughput (tokens/second)": 209.9892986983287,
  "Latency (ms/token) avg": 17.10508328395062,
  "Latency (ms/token) min": 15.019086,
  "Latency (ms/token) med": 16.993216,
  "Latency (ms/token) max": 17.897098,
  "Latency (ms/token) p(90)": 17.661877,
  "Latency (ms/token) p(95)": 17.702948,
  "Latency Request ms p(90)": 17629.19862,
  "Latency Request ms p(95)": 17654.815024,
  "Latency Request ms avg": 10968.316076925925,
  "Latency Request ms min": 8724.684987,
  "Latency Request ms med": 8815.318983,
  "Latency Request ms max": 17859.05337,
  "Latency Inference ms med": 8496.608346,
  "Latency Inference ms max": 8948.549464,
  "Latency Inference ms p(90)": 8830.938958,
  "Latency Inference ms p(95)": 8851.474158,
  "Latency Inference ms avg": 8552.541921876546,
  "Latency Inference ms min": 7509.543307999999,
  "Queue time ms med": 327.524728,
  "Queue time ms max": 8927.401438,
  "Queue time ms p(90)": 8811.169035,
  "Queue time ms p(95)": 8828.422353,
  "Queue time ms avg": 2415.5734127160495,
  "Queue time ms min": 0.041881999999999996
}