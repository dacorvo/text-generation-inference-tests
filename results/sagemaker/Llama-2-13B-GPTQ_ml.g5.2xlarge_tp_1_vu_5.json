{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-13B-GPTQ", "Instance": "ml.g5.2xlarge", "Tensor parallelism degree": 1, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 127, "Virtual Users": 5, "Duration (s)": 90,
"Throughput (tokens/second)": 71.70560103977112, "Latency (ms/token) avg": 73.7249624488189, "Latency (ms/token) min": 38.086532, "Latency (ms/token) med": 56.237484, "Latency (ms/token) max": 530.410387, "Latency (ms/token) p(90)": 99.1130128, "Latency (ms/token) p(95)": 124.79064749999976, "Latency Request ms p(90)": 5503.4596346, "Latency Request ms p(95)": 6556.301789, "Latency Request ms avg": 3486.4779930000004, "Latency Request ms min": 248.032819, "Latency Request ms med": 2995.652877, "Latency Request ms max": 9322.931073, "Latency Inference ms med": 2781.633414, "Latency Inference ms max": 9322.522187, "Latency Inference ms p(90)": 4759.569151, "Latency Inference ms p(95)": 4979.758543799999, "Latency Inference ms avg": 2998.163068582677, "Latency Inference ms min": 202.491843, "Queue time ms med": 74.741608, "Queue time ms max": 4318.450366, "Queue time ms p(90)": 1630.4484546, "Queue time ms p(95)": 1921.5319824, "Queue time ms avg": 487.1551351889764, "Queue time ms min": 0.034841000000000004}