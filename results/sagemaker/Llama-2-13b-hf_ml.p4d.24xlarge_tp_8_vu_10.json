{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-13b-hf", "Instance": "ml.p4d.24xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 595, "Virtual Users": 10, "Duration (s)": 90,
"Throughput (tokens/second)": 366.9431091006698, "Latency (ms/token) avg": 26.945801401680672, "Latency (ms/token) min": 22.72447, "Latency (ms/token) med": 25.751999, "Latency (ms/token) max": 109.039148, "Latency (ms/token) p(90)": 28.342919, "Latency (ms/token) p(95)": 30.5417124, "Latency Request ms p(90)": 1560.7101072, "Latency Request ms p(95)": 1660.2144363, "Latency Request ms avg": 1362.6090464689075, "Latency Request ms min": 67.279527, "Latency Request ms med": 1393.340578, "Latency Request ms max": 1913.396829, "Latency Inference ms med": 1283.856857, "Latency Inference ms max": 1536.03368, "Latency Inference ms p(90)": 1399.1984470000002, "Latency Inference ms p(95)": 1421.9593519, "Latency Inference ms avg": 1243.8203859327732, "Latency Inference ms min": 35.821029, "Queue time ms med": 117.034752, "Queue time ms max": 506.299459, "Queue time ms p(90)": 153.5911816, "Queue time ms p(95)": 350.7294118, "Queue time ms avg": 117.8698954722689, "Queue time ms min": 0.029338}