{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-70B-GPTQ", "Instance": "ml.g5.48xlarge", "Tensor parallelism degree": 8, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 22, "Virtual Users": 1, "Thorughput (tokens/second)": 13.484428356940631, "Latency (ms/token) avg": 123.95601154545456, "Latency (ms/token) min": 53.654342, "Latency (ms/token) med": 56.1448115, "Latency (ms/token) max": 1141.529097, "Latency (ms/token) p(90)": 158.48833240000013, "Latency (ms/token) p(95)": 179.22835579999997, "Latency Request ms p(90)": 5429.613414700002, "Latency Request ms p(95)": 8060.002591549998, "Latency Request ms avg": 3707.9806927272725, "Latency Request ms min": 2284.1177030000003, "Latency Request ms med": 2794.9389335, "Latency Request ms max": 9002.36396, "Latency Infernece ms med": 2794.4076995, "Latency Infernece ms max": 9001.768709, "Latency Infernece ms p(90)": 5427.462148700001, "Latency Infernece ms p(95)": 8059.583602249998, "Latency Infernece ms avg": 3707.1916589545453, "Latency Infernece ms min": 2283.058194, "Queue time ms med": 0.0546055, "Queue time ms max": 0.115263, "Queue time ms p(90)": 0.080268, "Queue time ms p(95)": 0.09655294999999998, "Queue time ms avg": 0.059761045454545456, "Queue time ms min": 0.03369}