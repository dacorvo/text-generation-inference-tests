{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 2,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 81,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 50.093047196945804,
  "Latency (ms/token) avg": 22.17718111111111,
  "Latency (ms/token) min": 18.575269,
  "Latency (ms/token) med": 19.986355,
  "Latency (ms/token) max": 105.002579,
  "Latency (ms/token) p(90)": 24.651244,
  "Latency (ms/token) p(95)": 25.849007,
  "Latency Request ms p(90)": 1178.674191,
  "Latency Request ms p(95)": 1236.615759,
  "Latency Request ms avg": 998.1425127407407,
  "Latency Request ms min": 84.310438,
  "Latency Request ms med": 964.294779,
  "Latency Request ms max": 1311.971429,
  "Latency Infernece ms med": 963.776681,
  "Latency Infernece ms max": 1308.9640670000001,
  "Latency Infernece ms p(90)": 1176.973802,
  "Latency Infernece ms p(95)": 1233.859262,
  "Latency Infernece ms avg": 997.1667400617283,
  "Latency Infernece ms min": 83.703976,
  "Queue time ms med": 0.044761,
  "Queue time ms max": 0.22200399999999998,
  "Queue time ms p(90)": 0.057651,
  "Queue time ms p(95)": 0.065592,
  "Queue time ms avg": 0.05042245679012346,
  "Queue time ms min": 0.0351
}