{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-7b-hf", "Instance": "ml.p4d.24xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 467, "Virtual Users": 10, "Duration (s)": 90,
"Throughput (tokens/second)": 269.1569189648927, "Latency (ms/token) avg": 40.259699021413276, "Latency (ms/token) min": 23.678948, "Latency (ms/token) med": 37.444304, "Latency (ms/token) max": 297.472199, "Latency (ms/token) p(90)": 40.284684, "Latency (ms/token) p(95)": 43.709189399999985, "Latency Request ms p(90)": 2055.0235508, "Latency Request ms p(95)": 2160.4310359, "Latency Request ms avg": 1857.6524130342611, "Latency Request ms min": 274.317479, "Latency Request ms med": 1899.7974, "Latency Request ms max": 2623.3239799999997, "Latency Inference ms med": 1866.284549, "Latency Inference ms max": 2390.3395600000003, "Latency Inference ms p(90)": 1981.9944498000002, "Latency Inference ms p(95)": 2064.1647531, "Latency Inference ms avg": 1795.2170419036402, "Latency Inference ms min": 208.327345, "Queue time ms med": 17.420755, "Queue time ms max": 768.306008, "Queue time ms p(90)": 125.69825480000006, "Queue time ms p(95)": 258.4750178, "Queue time ms avg": 61.367484021413276, "Queue time ms min": 0.033710000000000004}