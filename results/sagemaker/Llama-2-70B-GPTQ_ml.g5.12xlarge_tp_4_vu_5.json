{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-70B-GPTQ", "Instance": "ml.g5.12xlarge", "Tensor parallelism degree": 4, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 59, "Virtual Users": 5, "Duration (s)": 90,
"Throughput (tokens/second)": 33.33372399079303, "Latency (ms/token) avg": 190.57029242372883, "Latency (ms/token) min": 79.705894, "Latency (ms/token) med": 138.347928, "Latency (ms/token) max": 1447.831918, "Latency (ms/token) p(90)": 189.86151040000001, "Latency (ms/token) p(95)": 314.0749225999985, "Latency Request ms p(90)": 10196.9208184, "Latency Request ms p(95)": 14350.1524533, "Latency Request ms avg": 7499.912103101695, "Latency Request ms min": 1136.24834, "Latency Request ms med": 6942.013948, "Latency Request ms max": 14364.729889, "Latency Inference ms med": 6508.624279000001, "Latency Inference ms max": 14364.200463, "Latency Inference ms p(90)": 8502.0132276, "Latency Inference ms p(95)": 9475.2104241, "Latency Inference ms avg": 6820.9847939322035, "Latency Inference ms min": 1110.3862900000001, "Queue time ms med": 52.096867, "Queue time ms max": 5869.235993, "Queue time ms p(90)": 1785.7556118000002, "Queue time ms p(95)": 5861.5819319, "Queue time ms avg": 678.0600607966101, "Queue time ms min": 0.050112000000000004}