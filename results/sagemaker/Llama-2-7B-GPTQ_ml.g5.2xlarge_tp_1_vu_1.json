{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-7B-GPTQ", "Instance": "ml.g5.2xlarge", "Tensor parallelism degree": 1, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 70, "Virtual Users": 1, "Thorughput (tokens/second)": 41.027425895280764, "Latency (ms/token) avg": 24.354900199999996, "Latency (ms/token) min": 19.168455, "Latency (ms/token) med": 20.6848945, "Latency (ms/token) max": 103.175626, "Latency (ms/token) p(90)": 25.878725900000013, "Latency (ms/token) p(95)": 37.15260985, "Latency Request ms p(90)": 1296.2717621000006, "Latency Request ms p(95)": 1859.8565708499998, "Latency Request ms avg": 1218.6969791285717, "Latency Request ms min": 958.68167, "Latency Request ms med": 1035.0006615, "Latency Request ms max": 5159.342567000001, "Latency Infernece ms med": 1034.2447550000002, "Latency Infernece ms max": 5158.781338, "Latency Infernece ms p(90)": 1293.9363069000008, "Latency Infernece ms p(95)": 1857.6305320499998, "Latency Infernece ms avg": 1217.745036442857, "Latency Infernece ms min": 958.422756, "Queue time ms med": 0.0513555, "Queue time ms max": 0.073931, "Queue time ms p(90)": 0.059209000000000005, "Queue time ms p(95)": 0.064721, "Queue time ms avg": 0.053050885714285706, "Queue time ms min": 0.041049999999999996}