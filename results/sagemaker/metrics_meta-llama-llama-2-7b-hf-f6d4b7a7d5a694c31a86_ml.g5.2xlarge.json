{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 55,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 32.156894655559675,
  "Latency (ms/token) avg": 33.55270434545454,
  "Latency (ms/token) min": 30.846361,
  "Latency (ms/token) med": 31.208578,
  "Latency (ms/token) max": 93.265173,
  "Latency (ms/token) p(90)": 34.978637,
  "Latency (ms/token) p(95)": 36.654851699999995,
  "Latency Request ms p(90)": 1742.8303708,
  "Latency Request ms p(95)": 1769.7000349999998,
  "Latency Request ms avg": 1554.8765058181818,
  "Latency Request ms min": 187.92063,
  "Latency Request ms med": 1556.2373830000001,
  "Latency Request ms max": 1869.789939,
  "Latency Infernece ms med": 1555.827839,
  "Latency Infernece ms max": 1867.004402,
  "Latency Infernece ms p(90)": 1741.0710221999998,
  "Latency Infernece ms p(95)": 1767.8178818,
  "Latency Infernece ms avg": 1553.9805349818182,
  "Latency Infernece ms min": 186.530347,
  "Queue time ms med": 0.051321,
  "Queue time ms max": 0.065191,
  "Queue time ms p(90)": 0.057442400000000005,
  "Queue time ms p(95)": 0.06242269999999999,
  "Queue time ms avg": 0.05177523636363638,
  "Queue time ms min": 0.041661000000000004
}