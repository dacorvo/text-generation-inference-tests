{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 56,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 32.32661439016641,
  "Latency (ms/token) avg": 32.71217719642857,
  "Latency (ms/token) min": 30.645405,
  "Latency (ms/token) med": 30.982021000000003,
  "Latency (ms/token) max": 79.576015,
  "Latency (ms/token) p(90)": 33.6268515,
  "Latency (ms/token) p(95)": 34.5870915,
  "Latency Request ms p(90)": 1680.277357,
  "Latency Request ms p(95)": 1727.627011,
  "Latency Request ms avg": 1546.713163232143,
  "Latency Request ms min": 160.922055,
  "Latency Request ms med": 1546.556395,
  "Latency Request ms max": 1778.6285269999998,
  "Latency Infernece ms med": 1546.095128,
  "Latency Infernece ms max": 1775.8325450000002,
  "Latency Infernece ms p(90)": 1678.5708260000001,
  "Latency Infernece ms p(95)": 1725.5088934999999,
  "Latency Infernece ms avg": 1545.7831950178572,
  "Latency Infernece ms min": 159.15203,
  "Queue time ms med": 0.053426,
  "Queue time ms max": 0.06491,
  "Queue time ms p(90)": 0.062531,
  "Queue time ms p(95)": 0.063456,
  "Queue time ms avg": 0.05396146428571429,
  "Queue time ms min": 0.039471
}