{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 56,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 32.08473194817489,
  "Latency (ms/token) avg": 32.95621723214286,
  "Latency (ms/token) min": 30.891036,
  "Latency (ms/token) med": 31.1713205,
  "Latency (ms/token) max": 80.021489,
  "Latency (ms/token) p(90)": 33.883634,
  "Latency (ms/token) p(95)": 34.84091225,
  "Latency Request ms p(90)": 1692.7054045,
  "Latency Request ms p(95)": 1741.4091715,
  "Latency Request ms avg": 1558.3736239642858,
  "Latency Request ms min": 161.569848,
  "Latency Request ms med": 1557.475062,
  "Latency Request ms max": 1788.539025,
  "Latency Infernece ms med": 1557.0350815000002,
  "Latency Infernece ms max": 1785.7358279999999,
  "Latency Infernece ms p(90)": 1690.9903720000002,
  "Latency Infernece ms p(95)": 1739.35703475,
  "Latency Infernece ms avg": 1557.451028017857,
  "Latency Infernece ms min": 160.042979,
  "Queue time ms med": 0.050126000000000004,
  "Queue time ms max": 0.087392,
  "Queue time ms p(90)": 0.064191,
  "Queue time ms p(95)": 0.065661,
  "Queue time ms avg": 0.05310267857142857,
  "Queue time ms min": 0.043071
}