{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 55,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 32.38377487262304,
  "Latency (ms/token) avg": 32.695273436363635,
  "Latency (ms/token) min": 30.641992,
  "Latency (ms/token) med": 30.962235,
  "Latency (ms/token) max": 79.820378,
  "Latency (ms/token) p(90)": 33.5872078,
  "Latency (ms/token) p(95)": 34.552179,
  "Latency Request ms p(90)": 1679.7347286,
  "Latency Request ms p(95)": 1702.6366180999999,
  "Latency Request ms avg": 1543.983065490909,
  "Latency Request ms min": 161.030213,
  "Latency Request ms med": 1548.153946,
  "Latency Request ms max": 1778.322453,
  "Latency Infernece ms med": 1547.69604,
  "Latency Infernece ms max": 1775.5747390000001,
  "Latency Infernece ms p(90)": 1678.0527756,
  "Latency Infernece ms p(95)": 1700.8297579999999,
  "Latency Infernece ms avg": 1543.0905112545456,
  "Latency Infernece ms min": 159.640756,
  "Queue time ms med": 0.053621,
  "Queue time ms max": 0.07545099999999999,
  "Queue time ms p(90)": 0.062617,
  "Queue time ms p(95)": 0.067089,
  "Queue time ms avg": 0.05449585454545456,
  "Queue time ms min": 0.04419
}