{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 555,
  "Virtual Users": 20,
  "Thorughput (tokens/second)": 311.2869831522085,
  "Latency (ms/token) avg": 66.11835683603604,
  "Latency (ms/token) min": 43.509824,
  "Latency (ms/token) med": 61.624725,
  "Latency (ms/token) max": 692.223541,
  "Latency (ms/token) p(90)": 70.030735,
  "Latency (ms/token) p(95)": 70.98754529999997,
  "Latency Request ms p(90)": 3725.451952,
  "Latency Request ms p(95)": 3764.9399252,
  "Latency Request ms avg": 3212.469695563964,
  "Latency Request ms min": 446.203361,
  "Latency Request ms med": 3252.085705,
  "Latency Request ms max": 5041.50763,
  "Latency Infernece ms med": 3035.278773,
  "Latency Infernece ms max": 3631.6883199999997,
  "Latency Infernece ms p(90)": 3454.5429086,
  "Latency Infernece ms p(95)": 3532.0789726,
  "Latency Infernece ms avg": 2972.7748720576574,
  "Latency Infernece ms min": 226.423627,
  "Queue time ms med": 207.999546,
  "Queue time ms max": 1785.8202649999998,
  "Queue time ms p(90)": 258.1324976,
  "Queue time ms p(95)": 655.1435201999998,
  "Queue time ms avg": 238.1237315837838,
  "Queue time ms min": 0.058892
}