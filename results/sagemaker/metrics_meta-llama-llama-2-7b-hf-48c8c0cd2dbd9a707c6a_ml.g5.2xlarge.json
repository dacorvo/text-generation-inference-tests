{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 300,
  "Virtual Users": 10,
  "Thorughput (tokens/second)": 167.9054895238668,
  "Latency (ms/token) avg": 62.85176565666666,
  "Latency (ms/token) min": 38.617853,
  "Latency (ms/token) med": 56.085882,
  "Latency (ms/token) max": 427.96229,
  "Latency (ms/token) p(90)": 80.7348871,
  "Latency (ms/token) p(95)": 92.38973540000006,
  "Latency Request ms p(90)": 3907.2353517,
  "Latency Request ms p(95)": 4418.8344431,
  "Latency Request ms avg": 2977.865711346667,
  "Latency Request ms min": 262.845416,
  "Latency Request ms med": 2957.489506,
  "Latency Request ms max": 6003.505833,
  "Latency Infernece ms med": 2739.177126,
  "Latency Infernece ms max": 4859.086629,
  "Latency Infernece ms p(90)": 3647.7716250000003,
  "Latency Infernece ms p(95)": 4198.49063105,
  "Latency Infernece ms avg": 2754.7082757800003,
  "Latency Infernece ms min": 105.696067,
  "Queue time ms med": 208.86420950000002,
  "Queue time ms max": 1661.862554,
  "Queue time ms p(90)": 274.1072401,
  "Queue time ms p(95)": 542.7918715000004,
  "Queue time ms avg": 222.17317188,
  "Queue time ms min": 0.046960999999999996
}