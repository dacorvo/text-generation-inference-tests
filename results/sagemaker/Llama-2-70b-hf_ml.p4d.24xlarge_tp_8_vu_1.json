{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-70b-hf", "Instance": "ml.p4d.24xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 43, "Virtual Users": 1, "Duration (s)": 90,
"Throughput (tokens/second)": 24.51429279906098, "Latency (ms/token) avg": 43.13226197674419, "Latency (ms/token) min": 39.662616, "Latency (ms/token) med": 41.348543, "Latency (ms/token) max": 84.11013, "Latency (ms/token) p(90)": 46.275159599999995, "Latency (ms/token) p(95)": 47.0669483, "Latency Request ms p(90)": 2312.2482852, "Latency Request ms p(95)": 2344.9356262, "Latency Request ms avg": 2039.6264501627904, "Latency Request ms min": 85.665853, "Latency Request ms med": 2059.856661, "Latency Request ms max": 2544.880903, "Latency Inference ms med": 2057.806345, "Latency Inference ms max": 2543.802445, "Latency Inference ms p(90)": 2311.5408464, "Latency Inference ms p(95)": 2343.0619527999997, "Latency Inference ms avg": 2038.560301069767, "Latency Inference ms min": 84.11013, "Queue time ms med": 0.038037, "Queue time ms max": 0.097306, "Queue time ms p(90)": 0.061517000000000016, "Queue time ms p(95)": 0.0688773, "Queue time ms avg": 0.04409451162790698, "Queue time ms min": 0.030983}