{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.12xlarge",
  "Tensor parallelism degree": 4,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 693,
  "Virtual Users": 20,
  "Duration (s)": 90,
  "Throughput (tokens/second)": 449.9423027231205,
  "Latency (ms/token) avg": 50.22028511976912,
  "Latency (ms/token) min": 27.905574,
  "Latency (ms/token) med": 43.99524,
  "Latency (ms/token) max": 902.809571,
  "Latency (ms/token) p(90)": 54.2225886,
  "Latency (ms/token) p(95)": 56.205162200000004,
  "Latency Request ms p(90)": 2752.7576796,
  "Latency Request ms p(95)": 2890.9430634000005,
  "Latency Request ms avg": 2222.5071835829726,
  "Latency Request ms min": 198.375925,
  "Latency Request ms med": 2242.0430539999998,
  "Latency Request ms max": 3728.735168,
  "Latency Inference ms med": 2169.682033,
  "Latency Inference ms max": 2965.9633529999996,
  "Latency Inference ms p(90)": 2660.6955254,
  "Latency Inference ms p(95)": 2732.2625193999997,
  "Latency Inference ms avg": 2134.7977592164502,
  "Latency Inference ms min": 120.815019,
  "Queue time ms med": 69.369203,
  "Queue time ms max": 1564.2071259999998,
  "Queue time ms p(90)": 98.6109818,
  "Queue time ms p(95)": 251.15935099999996,
  "Queue time ms avg": 86.51359263636363,
  "Queue time ms min": 0.07416400000000001
}
