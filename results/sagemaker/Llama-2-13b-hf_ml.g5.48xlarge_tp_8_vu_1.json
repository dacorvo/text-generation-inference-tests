{"Host": "sagemaker", "Model Id": "meta-llama/Llama-2-13b-hf", "Instance": "ml.g5.48xlarge", "Tensor parallelism degree": 8, "quantization": "none", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 74, "Virtual Users": 1, "Thorughput (tokens/second)": 43.44589051024876, "Latency (ms/token) avg": 25.54973508108108, "Latency (ms/token) min": 19.599716, "Latency (ms/token) med": 21.6059755, "Latency (ms/token) max": 136.236754, "Latency (ms/token) p(90)": 32.3200433, "Latency (ms/token) p(95)": 34.3784661, "Latency Request ms p(90)": 1523.5107074000002, "Latency Request ms p(95)": 1638.48058695, "Latency Request ms avg": 1150.8568339324324, "Latency Request ms min": 273.949233, "Latency Request ms med": 1058.2421215, "Latency Request ms max": 1757.4608739999999, "Latency Infernece ms med": 1057.621405, "Latency Infernece ms max": 1754.24127, "Latency Infernece ms p(90)": 1520.8995108, "Latency Infernece ms p(95)": 1635.80484085, "Latency Infernece ms avg": 1149.820277945946, "Latency Infernece ms min": 272.473508, "Queue time ms med": 0.045365, "Queue time ms max": 0.08377, "Queue time ms p(90)": 0.06420400000000001, "Queue time ms p(95)": 0.06857199999999998, "Queue time ms avg": 0.04641348648648649, "Queue time ms min": 0.021341000000000002}