{
  "Host": "sagemaker",
  "Model Id": "meta-llama/Llama-2-7b-hf",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "none",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 141,
  "Virtual Users": 20,
  "Thorughput (tokens/second)": 272.9876399278933,
  "Latency (ms/token) avg": 90.94831643971631,
  "Latency (ms/token) min": 31.673969,
  "Latency (ms/token) med": 75.143699,
  "Latency (ms/token) max": 737.22568,
  "Latency (ms/token) p(90)": 95.761857,
  "Latency (ms/token) p(95)": 95.776485,
  "Latency Request ms p(90)": 4837.95866,
  "Latency Request ms p(95)": 4840.254973,
  "Latency Request ms avg": 3663.1695129645395,
  "Latency Request ms min": 628.662234,
  "Latency Request ms med": 3802.341534,
  "Latency Request ms max": 5282.882423,
  "Latency Infernece ms med": 3756.500883,
  "Latency Infernece ms max": 5227.750411999999,
  "Latency Infernece ms p(90)": 4787.2927819999995,
  "Latency Infernece ms p(95)": 4788.252678,
  "Latency Infernece ms avg": 3591.458350787234,
  "Latency Infernece ms min": 438.847077,
  "Queue time ms med": 19.606485,
  "Queue time ms max": 1891.577834,
  "Queue time ms p(90)": 49.253384,
  "Queue time ms p(95)": 53.499543,
  "Queue time ms avg": 69.65550064539006,
  "Queue time ms min": 0.03358
}