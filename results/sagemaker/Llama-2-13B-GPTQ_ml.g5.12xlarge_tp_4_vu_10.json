{"Host": "sagemaker", "Model Id": "TheBloke/Llama-2-13B-GPTQ", "Instance": "ml.g5.12xlarge", "Tensor parallelism degree": 4, "quantization": "gptq", "generated_tokens per request": 50, "Do Sample": true, "Number of requests": 255, "Virtual Users": 10, "Throughput (tokens/second)": 147.26087451708804, "Latency (ms/token) avg": 73.14708350196078, "Latency (ms/token) min": 28.865424, "Latency (ms/token) med": 54.627605, "Latency (ms/token) max": 678.099764, "Latency (ms/token) p(90)": 115.6658532, "Latency (ms/token) p(95)": 152.38538669999957, "Latency Request ms p(90)": 5886.851759, "Latency Request ms p(95)": 7098.3747987, "Latency Request ms avg": 3395.334990639216, "Latency Request ms min": 564.475193, "Latency Request ms med": 2770.8694729999997, "Latency Request ms max": 9862.285287, "Latency Inference ms med": 2690.500693, "Latency Inference ms max": 9514.277970000001, "Latency Inference ms p(90)": 4577.063845, "Latency Inference ms p(95)": 5783.3379783, "Latency Inference ms avg": 2869.1531584196077, "Latency Inference ms min": 339.590034, "Queue time ms med": 143.231226, "Queue time ms max": 4926.10783, "Queue time ms p(90)": 1831.714145799993, "Queue time ms p(95)": 4385.3515644, "Queue time ms avg": 525.1994769058824, "Queue time ms min": 0.036961}