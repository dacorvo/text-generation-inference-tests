configs:
# 7B Model
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 2
  vu_group: [1]
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 2
  vu_group: [5, 10, 20]
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 24
  vu_group: [1]
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 24
  vu_group: [5]
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 8
  sequence_length: 4096
  tp_degree: 24
  vu_group: [10, 20]
# 13B Model
- model_id: meta-llama/Llama-2-13b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 24
  vu_group: [1]
- model_id: meta-llama/Llama-2-13b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 24
  vu_group: [5]
- model_id: meta-llama/Llama-2-13b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 8
  sequence_length: 4096
  tp_degree: 24
  vu_group: [10, 20]
# 70B Model
- model_id: meta-llama/Llama-2-70b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 24
  vu_group: [1]
- model_id: meta-llama/Llama-2-70b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 24
  vu_group: [5, 10, 20]
