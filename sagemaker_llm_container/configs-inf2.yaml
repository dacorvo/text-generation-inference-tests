configs:
# 7B Model
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 2
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 2
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 24
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 24
- model_id: meta-llama/Llama-2-7b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 8
  sequence_length: 4096
  tp_degree: 24
# 13B Model
- model_id: meta-llama/Llama-2-13b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 24
- model_id: meta-llama/Llama-2-13b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 24
- model_id: meta-llama/Llama-2-13b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 8
  sequence_length: 4096
  tp_degree: 24
# 70B Model
- model_id: meta-llama/Llama-2-70b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 1
  sequence_length: 4096
  tp_degree: 24
- model_id: meta-llama/Llama-2-70b-hf
  instance_type: ml.inf2.48xlarge
  batch_size: 4
  sequence_length: 4096
  tp_degree: 24
