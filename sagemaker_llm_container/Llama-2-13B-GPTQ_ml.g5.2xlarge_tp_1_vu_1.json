{
  "Host": "sagemaker",
  "Model Id": "TheBloke/Llama-2-13B-GPTQ",
  "Instance": "ml.g5.2xlarge",
  "Tensor parallelism degree": 1,
  "quantization": "gptq",
  "generated_tokens per request": 50,
  "Do Sample": true,
  "Number of requests": 45,
  "Virtual Users": 1,
  "Thorughput (tokens/second)": 25.82455547563257,
  "Latency (ms/token) avg": 38.71939902222222,
  "Latency (ms/token) min": 28.295919,
  "Latency (ms/token) med": 31.01256,
  "Latency (ms/token) max": 125.795472,
  "Latency (ms/token) p(90)": 60.9803062,
  "Latency (ms/token) p(95)": 66.84025119999998,
  "Latency Request ms p(90)": 3050.4097040000006,
  "Latency Request ms p(95)": 3344.0204759999992,
  "Latency Request ms avg": 1936.1417487777783,
  "Latency Request ms min": 1415.076779,
  "Latency Request ms med": 1551.670561,
  "Latency Request ms max": 6290.306708,
  "Latency Infernece ms med": 1550.628008,
  "Latency Infernece ms max": 6289.773621,
  "Latency Infernece ms p(90)": 3049.0153222,
  "Latency Infernece ms p(95)": 3342.0125831999994,
  "Latency Infernece ms avg": 1935.183931555556,
  "Latency Infernece ms min": 1414.7959859999999,
  "Queue time ms med": 0.053509999999999995,
  "Queue time ms max": 0.066001,
  "Queue time ms p(90)": 0.064059,
  "Queue time ms p(95)": 0.065251,
  "Queue time ms avg": 0.0546838,
  "Queue time ms min": 0.045521
}